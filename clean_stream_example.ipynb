{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, json\n",
    "from clean import *\n",
    "from datetime import *\n",
    "from dateutil import parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#os.chdir('stream-tweets-examples/TheBigShort/')\n",
    "path_to_json = 'stream-tweets-examples/TheBigShort/'\n",
    "json_files = [pos_json for pos_json in os.listdir(path_to_json) if pos_json.endswith('.json')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(json_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mark Baum is most human character in The Big Short - felt like his anguish is supposed to be film's conscience. But he's a Wall St banker.\n",
      "RT @Callum_Thomas: Fed on hold + BoJ easing could be the catalyst for a big ole short squeeze in emerging markets.... https://t.co/FhA0lOVeâ€¦\n",
      "@aliciamalone Still a big surprise that The Big Short is now such a big contender even for the Oscars. Good film but this was not expected.\n",
      "Elencos de Spotlight y The Big Short, favoritos en los Premios SAG https://t.co/tyTzWfw8hw\n",
      "RT @Callum_Thomas: Fed on hold + BoJ easing could be the catalyst for a big ole short squeeze in emerging markets.... https://t.co/FhA0lOVeâ€¦\n",
      "Highly recommend The Big Short. Mega interesting.\n",
      "Greedy American system: lays to the people takes from the poor protect bankers/finance at all costs #thebigshort https://t.co/BFVkD0zXDL\n",
      "Made up. Hair did. ðŸ’‹ðŸ•¶ðŸ“½ðŸŽ­ @sagawards bound!  Go Christian Bale! Go  #thebigshort !  Whateverâ€¦ https://t.co/iXT0LTjy4Q\n",
      "Watched The Big Short. None the wiser\n",
      "The Big Short was bloody good\n",
      "Greedy American system: lies to the people takes from the poor protect bankers/finance at all costs #thebigshort https://t.co/38gAtzhTgFâ€¦\n",
      "The Big Short &gt;&gt;&gt; The Revenant\n",
      "#TheBigShort,' 'Spotlight' to Vie at SAGs https://t.co/qXJwxXmbL5 https://t.co/UvyE9iH0Ey\n",
      "The Big Short je maestralan film, ali nije za svakoga.\n",
      "Saw The Big Short and I cried. Heartbreaking.\n",
      "J'ai bien aimÃ© the big short\n",
      "RT @TNTLA: De Caballero de la Noche a nominado por The Big Short. Â¡Feliz cumpleaÃ±os Christian Bale! https://t.co/f0XL9uus1n\n",
      "The Big Short was v. good\n",
      "RT @ParamountUK: Thanks to @SelenaGomez, you can't lose. ðŸ’µ\n",
      "#TheBigShort is in cinemas everywhere now. https://t.co/x07Z6bEmqp\n",
      "anyway this lady just bullied me into letting her into the big short bc her bus was late and \"it would be cruel not to at this point\"\n",
      "My totally scientific #sagawards predications: #TheBigShort, Leo, Brie, Alicia and Jacob Tremblay.\n",
      "Just saw The Big Short. Absolutely ace film.\n",
      "@kuber42 quaz the dog https://t.co/ZYoJcwtfRG\n",
      "While I thoroughly enjoyed #TheBigShort, it really seems like it was edited in one long coke-filled weekend.\n",
      "Humanity led by the nose: #TheBigShort  https://t.co/lA8Tnkkuyf\n",
      "anyway this lady just bullied me into letting her into the big short bc her bus was la https://t.co/NUMNeFFQBL https://t.co/XOE54nFPYm\n",
      "#BREAKING: #SWEDEN wants to grant this guy Asylum !!!!Watch: https://t.co/G7WQ3SEVbI https://t.co/dssHPZq9tf\n",
      "@Andrew_lowe_pro thanks mate. You seen THE BIG SHORT yet? On pictures.. It's a hard watch like but great true story\n",
      "@TheBigShort - brilliant film, interesting, educational and depressing #bankersarecrooks\n",
      "RT @ParamountUK: Thanks to @SelenaGomez, you can't lose. ðŸ’µ\n",
      "#TheBigShort is in cinemas everywhere now. https://t.co/x07Z6bEmqp\n",
      "RT @ParamountUK: Thanks to @SelenaGomez, you can't lose. ðŸ’µ\n",
      "#TheBigShort is in cinemas everywhere now. https://t.co/x07Z6bEmqp\n",
      "Join me while I'll be talking about the SAG awards LIVE tonight. ( Hoping for DiCaprio and The Big Short)! #sagawards\n",
      "LOS ANGELES (Reuters) - Hollywood producers named \"The Big Short\" the best film of 2015 at a glitzy awards show on Saturday, which was\n",
      "RT @aliciamalone: #SAGAwards predictions: Leonardo DiCaprio, Brie Larson, Christian Bale, Alicia Vikander, The Big Short (but this year it â€¦\n",
      "RT @SomeKindofJesse: Saw The Big Short and I cried. Heartbreaking.\n",
      "I'm at Showcase Legacy Place for The Big Short in Dedham, MA https://t.co/kFv5jhitz7\n"
     ]
    }
   ],
   "source": [
    "thebigshort = []\n",
    "for js in json_files:\n",
    "    with open(path_to_json+js) as infile:\n",
    "        sample = json.load(infile)\n",
    "    #print sample['text']\n",
    "    sample['text'] = tokenize(sample['text'])\n",
    "    sample['created_at'] = parser.parse(str(sample['created_at'])) \n",
    "    sample['created_at'] = str(sample['created_at'])\n",
    "    thebigshort.append(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mark baum human character big short felt anguish supposed films conscience hes wall st banker\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "u'mark baum human character big short felt anguish supposed films conscience hes wall st banker'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print sample['text']\n",
    "tokenize(sample['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'contributors': None,\n",
       " u'coordinates': None,\n",
       " u'created_at': '2016-01-30 22:47:12+00:00',\n",
       " u'entities': {u'hashtags': [],\n",
       "  u'symbols': [],\n",
       "  u'urls': [],\n",
       "  u'user_mentions': []},\n",
       " u'favorite_count': 0,\n",
       " u'favorited': False,\n",
       " u'filter_level': u'low',\n",
       " u'geo': None,\n",
       " u'id': 693566157832503297,\n",
       " u'id_str': u'693566157832503297',\n",
       " u'in_reply_to_screen_name': None,\n",
       " u'in_reply_to_status_id': None,\n",
       " u'in_reply_to_status_id_str': None,\n",
       " u'in_reply_to_user_id': None,\n",
       " u'in_reply_to_user_id_str': None,\n",
       " u'is_quote_status': False,\n",
       " u'lang': u'en',\n",
       " u'place': None,\n",
       " u'retweet_count': 0,\n",
       " u'retweeted': False,\n",
       " u'source': u'<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>',\n",
       " u'text': u'mark baum human character big short felt anguish supposed films conscience hes wall st banker',\n",
       " u'timestamp_ms': u'1454194032520',\n",
       " u'truncated': False,\n",
       " u'user': {u'contributors_enabled': False,\n",
       "  u'created_at': u'Thu Dec 29 23:09:03 +0000 2011',\n",
       "  u'default_profile': False,\n",
       "  u'default_profile_image': False,\n",
       "  u'description': u'American Studies and labor history.',\n",
       "  u'favourites_count': 373,\n",
       "  u'follow_request_sent': None,\n",
       "  u'followers_count': 493,\n",
       "  u'following': None,\n",
       "  u'friends_count': 1685,\n",
       "  u'geo_enabled': True,\n",
       "  u'id': 450156705,\n",
       "  u'id_str': u'450156705',\n",
       "  u'is_translator': False,\n",
       "  u'lang': u'en',\n",
       "  u'listed_count': 17,\n",
       "  u'location': None,\n",
       "  u'name': u'Joe',\n",
       "  u'notifications': None,\n",
       "  u'profile_background_color': u'C0DEED',\n",
       "  u'profile_background_image_url': u'http://pbs.twimg.com/profile_background_images/437676789750456320/gxthqP9T.jpeg',\n",
       "  u'profile_background_image_url_https': u'https://pbs.twimg.com/profile_background_images/437676789750456320/gxthqP9T.jpeg',\n",
       "  u'profile_background_tile': False,\n",
       "  u'profile_banner_url': u'https://pbs.twimg.com/profile_banners/450156705/1416697627',\n",
       "  u'profile_image_url': u'http://pbs.twimg.com/profile_images/526810260422791168/-CV4Wj_c_normal.jpeg',\n",
       "  u'profile_image_url_https': u'https://pbs.twimg.com/profile_images/526810260422791168/-CV4Wj_c_normal.jpeg',\n",
       "  u'profile_link_color': u'0084B4',\n",
       "  u'profile_sidebar_border_color': u'FFFFFF',\n",
       "  u'profile_sidebar_fill_color': u'DDEEF6',\n",
       "  u'profile_text_color': u'333333',\n",
       "  u'profile_use_background_image': True,\n",
       "  u'protected': False,\n",
       "  u'screen_name': u'jpbng',\n",
       "  u'statuses_count': 6288,\n",
       "  u'time_zone': u'London',\n",
       "  u'url': None,\n",
       "  u'utc_offset': 0,\n",
       "  u'verified': False}}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thebigshort[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#os.chdir('stream-tweets-examples/TheBigShort/')\n",
    "path_to_json = 'stream-tweets-examples/BradPitt/'\n",
    "json_files = [pos_json for pos_json in os.listdir(path_to_json) if pos_json.endswith('.json')]\n",
    "\n",
    "BradPitt = []\n",
    "for js in json_files:\n",
    "    with open(path_to_json+js) as infile:\n",
    "        sample = json.load(infile)\n",
    "    sample['text'] = tokenize(sample['text'])\n",
    "    sample['created_at'] = parser.parse(str(sample['created_at']))\n",
    "    sample['created_at'] = str(sample['created_at'])\n",
    "    BradPitt.append(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'lara croft tomb raider dvd sensormatic angelina jolie'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BradPitt[2]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#os.chdir('stream-tweets-examples/TheBigShort/')\n",
    "path_to_json = 'stream-tweets-examples/LeoDiCaprio/'\n",
    "json_files = [pos_json for pos_json in os.listdir(path_to_json) if pos_json.endswith('.json')]\n",
    "\n",
    "LeoDiCaprio = []\n",
    "for js in json_files:\n",
    "    with open(path_to_json+js) as infile:\n",
    "        sample = json.load(infile)\n",
    "    sample['text'] = tokenize(sample['text'])\n",
    "    sample['created_at'] = parser.parse(str(sample['created_at'])) \n",
    "    sample['created_at'] = str(sample['created_at'])\n",
    "    LeoDiCaprio.append(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ecevitlaikci gÃ¼ldÃ¼rmeyen leonardo dicaprio ve oscar mizahlarÄ±\n"
     ]
    }
   ],
   "source": [
    "print LeoDiCaprio[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"stream-tweets-examples/thebigshort.json\", \"w\") as f:\n",
    "    json.dump(thebigshort, f, indent=4, sort_keys=True)\n",
    "    \n",
    "with open(\"stream-tweets-examples/BradPitt.json\", \"w\") as f:\n",
    "    json.dump(BradPitt, f, indent=4, sort_keys=True)\n",
    "    \n",
    "with open(\"stream-tweets-examples/LeoDiCaprio.json\", \"w\") as f:\n",
    "    json.dump(LeoDiCaprio, f, indent=4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus_thebigshort = ' '.join([l['text'] for l in thebigshort])#[l[text] for l in thebigshort]thebigshort[2]['text']\n",
    "delete_list = ['big','short']\n",
    "for word in delete_list:\n",
    "    corpus_thebigshort = corpus_thebigshort.replace(word, \"\")\n",
    "print corpus_thebigshort\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "wordcloud = WordCloud(background_color='white').generate(corpus_thebigshort)\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.imshow(wordcloud)\n",
    "plt.savefig('wordcloud_bigshort1')\n",
    "plt.axis(\"off\")\n",
    "\n",
    "\n",
    "# take relative word frequencies into account, lower max_font_size\n",
    "wordcloud = WordCloud(background_color='white',max_font_size=40, relative_scaling=.5).generate(corpus_thebigshort)\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.imshow(wordcloud)\n",
    "plt.savefig('wordcloud_bigshort2')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/Users/wyshi/Desktop/stat222/twitter-oscars'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import path\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "d = path.dirname(__file__)\n",
    "\n",
    "# Read the whole text.\n",
    "text = open(path.join(d, 'constitution.txt')).read()\n",
    "\n",
    "# Generate a word cloud image\n",
    "wordcloud = WordCloud().generate(text)\n",
    "\n",
    "# Display the generated image:\n",
    "# the matplotlib way:\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# take relative word frequencies into account, lower max_font_size\n",
    "wordcloud = WordCloud(max_font_size=40, relative_scaling=.5).generate(text)\n",
    "plt.figure()\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "d = path.dirname(__file__)\n",
    "\n",
    "# Read the whole text.\n",
    "text = open(path.join(d, 'alice.txt')).read()\n",
    "\n",
    "# read the mask image\n",
    "# taken from\n",
    "# http://www.stencilry.org/stencils/movies/alice%20in%20wonderland/255fk.jpg\n",
    "alice_mask = np.array(Image.open(path.join(d, \"alice_mask.png\")))\n",
    "\n",
    "wc = WordCloud(background_color=\"white\", max_words=2000, mask=alice_mask,\n",
    "               stopwords=STOPWORDS.add(\"said\"))\n",
    "# generate word cloud\n",
    "wc.generate(text)\n",
    "\n",
    "# store to file\n",
    "wc.to_file(path.join(d, \"alice.png\"))\n",
    "\n",
    "# show\n",
    "plt.imshow(wc)\n",
    "plt.axis(\"off\")\n",
    "plt.figure()\n",
    "plt.imshow(alice_mask, cmap=plt.cm.gray)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
